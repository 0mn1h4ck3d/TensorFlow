{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/0mn1h4ck3d/TensorFlow/blob/main/animals.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QlUQo7AgDr4J"
      },
      "source": [
        "# This part is responsible for transforming Datasets into training and test."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wDeyUitqwJVt",
        "outputId": "6a0f23a8-2f35-4dd5-97fc-8a56528b7a2f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Mounting Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "8kOqk7Im1fRK"
      },
      "outputs": [],
      "source": [
        "# Unzipping file\n",
        "import zipfile\n",
        "zip_ref = zipfile.ZipFile(\"/content/drive/MyDrive/TensorFlow/Animals.zip\")\n",
        "zip_ref.extractall()\n",
        "zip_ref.close()\n",
        "!rm /content/Animals/.DS_Store"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dJYP9Z0SsrMP",
        "outputId": "f41bbafa-aa2b-4827-9a60-8f7143e4bf77"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 10 directories and 0 images in '/content/Animals'\n",
            "There are 0 directories and 1668 images in '/content/Animals/cat'\n",
            "There are 0 directories and 1866 images in '/content/Animals/cow'\n",
            "There are 0 directories and 2112 images in '/content/Animals/butterfly'\n",
            "There are 0 directories and 1446 images in '/content/Animals/elephant'\n",
            "There are 0 directories and 4821 images in '/content/Animals/spider'\n",
            "There are 0 directories and 3098 images in '/content/Animals/chicken'\n",
            "There are 0 directories and 4863 images in '/content/Animals/dog'\n",
            "There are 0 directories and 2623 images in '/content/Animals/horse'\n",
            "There are 0 directories and 1820 images in '/content/Animals/sheep'\n",
            "There are 0 directories and 1862 images in '/content/Animals/squirrel'\n"
          ]
        }
      ],
      "source": [
        "# Display data info\n",
        "import os\n",
        "\n",
        "for dirpath, dirnames, filenames in os.walk(\"/content/Animals\"):\n",
        "  print(f\"There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "qdG30eOyNswr"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import shutil\n",
        "\n",
        "# Set the path to the Animals folder\n",
        "animals_folder = \"/content/Animals\"\n",
        "\n",
        "# Set the percentage of images to use for testing\n",
        "test_percentage = 0.2\n",
        "\n",
        "# Create train and test folders in the Animals folder\n",
        "os.makedirs(os.path.join(animals_folder, \"train\"), exist_ok=True)\n",
        "os.makedirs(os.path.join(animals_folder, \"test\"), exist_ok=True)\n",
        "\n",
        "# Loop through each class folder in the Animals folder\n",
        "for class_folder in os.listdir(animals_folder):\n",
        "    if os.path.isdir(os.path.join(animals_folder, class_folder)):\n",
        "        # Create train and test subfolders for the current class\n",
        "        os.makedirs(os.path.join(animals_folder, \"train\", class_folder), exist_ok=True)\n",
        "        os.makedirs(os.path.join(animals_folder, \"test\", class_folder), exist_ok=True)\n",
        "\n",
        "        # Get a list of all images in the current class folder\n",
        "        images = [f for f in os.listdir(os.path.join(animals_folder, class_folder)) if f.endswith(\".jpeg\") or f.endswith(\".jpg\")]\n",
        "\n",
        "        # Shuffle the images randomly\n",
        "        random.shuffle(images)\n",
        "\n",
        "        # Calculate the number of images to use for testing\n",
        "        num_test_images = int(len(images) * test_percentage)\n",
        "\n",
        "        # Copy the first num_test_images images to the test folder\n",
        "        for i in range(num_test_images):\n",
        "            image = images[i]\n",
        "            src_path = os.path.join(animals_folder, class_folder, image)\n",
        "            dst_path = os.path.join(animals_folder, \"test\", class_folder, image)\n",
        "            shutil.copyfile(src_path, dst_path)\n",
        "\n",
        "        # Copy the remaining images to the train folder\n",
        "        for i in range(num_test_images, len(images)):\n",
        "            image = images[i]\n",
        "            src_path = os.path.join(animals_folder, class_folder, image)\n",
        "            dst_path = os.path.join(animals_folder, \"train\", class_folder, image)\n",
        "            shutil.copyfile(src_path, dst_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fnErrZ_VXNJk",
        "outputId": "56a3f5e5-4ca2-48e4-a748-53ce4261fe8e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 12 directories and 0 images in '/content/Animals'\n",
            "There are 0 directories and 1668 images in '/content/Animals/cat'\n",
            "There are 0 directories and 1866 images in '/content/Animals/cow'\n",
            "There are 0 directories and 2112 images in '/content/Animals/butterfly'\n",
            "There are 0 directories and 1446 images in '/content/Animals/elephant'\n",
            "There are 0 directories and 4821 images in '/content/Animals/spider'\n",
            "There are 0 directories and 3098 images in '/content/Animals/chicken'\n",
            "There are 0 directories and 4863 images in '/content/Animals/dog'\n",
            "There are 0 directories and 2623 images in '/content/Animals/horse'\n",
            "There are 12 directories and 0 images in '/content/Animals/test'\n",
            "There are 0 directories and 333 images in '/content/Animals/test/cat'\n",
            "There are 0 directories and 373 images in '/content/Animals/test/cow'\n",
            "There are 0 directories and 414 images in '/content/Animals/test/butterfly'\n",
            "There are 0 directories and 287 images in '/content/Animals/test/elephant'\n",
            "There are 0 directories and 963 images in '/content/Animals/test/spider'\n",
            "There are 0 directories and 619 images in '/content/Animals/test/chicken'\n",
            "There are 0 directories and 972 images in '/content/Animals/test/dog'\n",
            "There are 0 directories and 524 images in '/content/Animals/test/horse'\n",
            "There are 0 directories and 0 images in '/content/Animals/test/test'\n",
            "There are 0 directories and 0 images in '/content/Animals/test/train'\n",
            "There are 0 directories and 364 images in '/content/Animals/test/sheep'\n",
            "There are 0 directories and 372 images in '/content/Animals/test/squirrel'\n",
            "There are 12 directories and 0 images in '/content/Animals/train'\n",
            "There are 0 directories and 1334 images in '/content/Animals/train/cat'\n",
            "There are 0 directories and 1493 images in '/content/Animals/train/cow'\n",
            "There are 0 directories and 1658 images in '/content/Animals/train/butterfly'\n",
            "There are 0 directories and 1151 images in '/content/Animals/train/elephant'\n",
            "There are 0 directories and 3856 images in '/content/Animals/train/spider'\n",
            "There are 0 directories and 2479 images in '/content/Animals/train/chicken'\n",
            "There are 0 directories and 3891 images in '/content/Animals/train/dog'\n",
            "There are 0 directories and 2099 images in '/content/Animals/train/horse'\n",
            "There are 0 directories and 0 images in '/content/Animals/train/test'\n",
            "There are 0 directories and 0 images in '/content/Animals/train/train'\n",
            "There are 0 directories and 1456 images in '/content/Animals/train/sheep'\n",
            "There are 0 directories and 1490 images in '/content/Animals/train/squirrel'\n",
            "There are 0 directories and 1820 images in '/content/Animals/sheep'\n",
            "There are 0 directories and 1862 images in '/content/Animals/squirrel'\n"
          ]
        }
      ],
      "source": [
        "# Display data info\n",
        "import os\n",
        "\n",
        "for dirpath, dirnames, filenames in os.walk(\"/content/Animals\"):\n",
        "  print(f\"There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Ds3XvyiZaRt"
      },
      "source": [
        "## Deleting every folder instead of 'train' and 'test'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "tLOq8XK0ZOnE"
      },
      "outputs": [],
      "source": [
        "# Set the path to the directory containing the folders\n",
        "directory_path = \"/content/Animals\"\n",
        "\n",
        "# Set the list of folders to exclude from deletion\n",
        "exclude_folders = [\"train\", \"test\"]\n",
        "\n",
        "# Loop through each folder in the directory\n",
        "for folder_name in os.listdir(directory_path):\n",
        "    # Check if the current item is a directory\n",
        "    if os.path.isdir(os.path.join(directory_path, folder_name)):\n",
        "        # Check if the current folder is in the exclude_folders list\n",
        "        if folder_name not in exclude_folders:\n",
        "            # Delete the current folder and all its contents\n",
        "            shutil.rmtree(os.path.join(directory_path, folder_name))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o_9Ll0PaZe3X"
      },
      "source": [
        "## Deleting only 'test' and 'train' folders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "5OaWKW3jZh-K"
      },
      "outputs": [],
      "source": [
        "# Set the path to the directory containing the folders\n",
        "directory_path = \"/content/Animals/test\"\n",
        "\n",
        "# Set the list of folders to delete\n",
        "folders_to_delete = [\"train\", \"test\"]\n",
        "\n",
        "# Loop through each folder in the directory\n",
        "for folder_name in os.listdir(directory_path):\n",
        "    # Check if the current item is a directory and if its name is in the folders_to_delete list\n",
        "    if os.path.isdir(os.path.join(directory_path, folder_name)) and folder_name in folders_to_delete:\n",
        "        # Delete the current folder and all its contents\n",
        "        shutil.rmtree(os.path.join(directory_path, folder_name))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "RSOLb1RsZ-QO"
      },
      "outputs": [],
      "source": [
        "directory_path1 = \"/content/Animals/train\"\n",
        "\n",
        "# Set the list of folders to delete\n",
        "folders_to_delete = [\"train\", \"test\"]\n",
        "\n",
        "# Loop through each folder in the directory\n",
        "for folder_name in os.listdir(directory_path1):\n",
        "    # Check if the current item is a directory and if its name is in the folders_to_delete list\n",
        "    if os.path.isdir(os.path.join(directory_path1, folder_name)) and folder_name in folders_to_delete:\n",
        "        # Delete the current folder and all its contents\n",
        "        shutil.rmtree(os.path.join(directory_path1, folder_name))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LarXOuDyZxSC",
        "outputId": "5eed0f66-5c5b-4bdf-d9eb-2c4eb7cc7730"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 2 directories and 0 images in '/content/Animals'\n",
            "There are 10 directories and 0 images in '/content/Animals/test'\n",
            "There are 0 directories and 333 images in '/content/Animals/test/cat'\n",
            "There are 0 directories and 373 images in '/content/Animals/test/cow'\n",
            "There are 0 directories and 414 images in '/content/Animals/test/butterfly'\n",
            "There are 0 directories and 287 images in '/content/Animals/test/elephant'\n",
            "There are 0 directories and 963 images in '/content/Animals/test/spider'\n",
            "There are 0 directories and 619 images in '/content/Animals/test/chicken'\n",
            "There are 0 directories and 972 images in '/content/Animals/test/dog'\n",
            "There are 0 directories and 524 images in '/content/Animals/test/horse'\n",
            "There are 0 directories and 364 images in '/content/Animals/test/sheep'\n",
            "There are 0 directories and 372 images in '/content/Animals/test/squirrel'\n",
            "There are 10 directories and 0 images in '/content/Animals/train'\n",
            "There are 0 directories and 1334 images in '/content/Animals/train/cat'\n",
            "There are 0 directories and 1493 images in '/content/Animals/train/cow'\n",
            "There are 0 directories and 1658 images in '/content/Animals/train/butterfly'\n",
            "There are 0 directories and 1151 images in '/content/Animals/train/elephant'\n",
            "There are 0 directories and 3856 images in '/content/Animals/train/spider'\n",
            "There are 0 directories and 2479 images in '/content/Animals/train/chicken'\n",
            "There are 0 directories and 3891 images in '/content/Animals/train/dog'\n",
            "There are 0 directories and 2099 images in '/content/Animals/train/horse'\n",
            "There are 0 directories and 1456 images in '/content/Animals/train/sheep'\n",
            "There are 0 directories and 1490 images in '/content/Animals/train/squirrel'\n"
          ]
        }
      ],
      "source": [
        "# Display data info\n",
        "import os\n",
        "\n",
        "for dirpath, dirnames, filenames in os.walk(\"/content/Animals\"):\n",
        "  print(f\"There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'\")\n",
        "\n",
        "!rm -r __MACOSX"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WyttyI-9VepK"
      },
      "source": [
        "# Become one with the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iPWN64gmUq1J",
        "outputId": "d7256487-3eb5-4470-cd06-f76a6bcc8037"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 20907 images belonging to 10 classes.\n",
            "Found 5221 images belonging to 10 classes.\n"
          ]
        }
      ],
      "source": [
        "# Create ImageDataGenerator and turn data into batches\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "IMAGE_SHAPE = (224, 224)\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "train_dir = \"/content/Animals/train\"\n",
        "test_dir = \"/content/Animals/test\"\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale=1/255.)\n",
        "test_datagen = ImageDataGenerator(rescale=1/255.)\n",
        "\n",
        "train_norm = train_datagen.flow_from_directory(train_dir,\n",
        "                                               target_size=IMAGE_SHAPE,\n",
        "                                               batch_size=BATCH_SIZE,\n",
        "                                               class_mode=\"categorical\")\n",
        "\n",
        "test_norm = test_datagen.flow_from_directory(test_dir,\n",
        "                                             target_size=IMAGE_SHAPE,\n",
        "                                             batch_size=BATCH_SIZE,\n",
        "                                             class_mode=\"categorical\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C0MEp-PJc4YW"
      },
      "source": [
        "# Creating and putting data into model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uBSOILRTgNSX"
      },
      "source": [
        "## Creating model using TensorFlow Hub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "3ps-2vFP9gKX",
        "outputId": "66399592-1fe9-4917-9454-888680b8d843"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94668760/94668760 [==============================] - 0s 0us/step\n",
            "Epoch 1/10\n",
            "  4/654 [..............................] - ETA: 1:12:55 - loss: 3.6026 - accuracy: 0.2422"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-57cf1ffa07b8>\u001b[0m in \u001b[0;36m<cell line: 42>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;31m# Assuming train_norm and test_norm are your prepared datasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m history = model.fit(train_norm,\n\u001b[0m\u001b[1;32m     43\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1805\u001b[0m                         ):\n\u001b[1;32m   1806\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1807\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1808\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1809\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 832\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    866\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 868\u001b[0;31m       return tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    869\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1321\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1322\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1485\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1486\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1487\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1488\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Data augmentation\n",
        "data_augmentation = tf.keras.Sequential([\n",
        "  tf.keras.layers.experimental.preprocessing.RandomFlip(\"horizontal_and_vertical\"),\n",
        "  tf.keras.layers.experimental.preprocessing.RandomRotation(0.2),\n",
        "  tf.keras.layers.experimental.preprocessing.RandomZoom(0.2),\n",
        "])\n",
        "\n",
        "# Import ResNet50V2 model without the top layer, pretrained on ImageNet\n",
        "base_model = tf.keras.applications.ResNet50V2(include_top=False, weights='imagenet', input_shape=(224, 224, 3))\n",
        "\n",
        "# Freeze the convolutional base to start\n",
        "base_model.trainable = False\n",
        "\n",
        "# Create the model\n",
        "model = tf.keras.Sequential([\n",
        "    data_augmentation,  # Add data augmentation\n",
        "    base_model,\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.BatchNormalization(),  # Batch normalization\n",
        "    tf.keras.layers.Dense(512, activation=\"relu\", kernel_regularizer=tf.keras.regularizers.l2(0.001)),  # L2 regularization\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(10, activation=\"softmax\")\n",
        "])\n",
        "\n",
        "# Compile the model with a learning rate scheduler\n",
        "model.compile(loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "              optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "# Learning rate scheduler\n",
        "lr_scheduler = tf.keras.callbacks.ReduceLROnPlateau(\n",
        "    monitor='val_loss',\n",
        "    factor=0.1,\n",
        "    patience=2,\n",
        "    min_lr=1e-6,\n",
        "    mode='auto',\n",
        "    verbose=1)\n",
        "\n",
        "# Assuming train_norm and test_norm are your prepared datasets\n",
        "history = model.fit(train_norm,\n",
        "                    epochs=10,\n",
        "                    validation_data=test_norm,\n",
        "                    callbacks=[lr_scheduler])\n",
        "\n",
        "# Fine-tuning phase (optional but recommended after the initial training)\n",
        "base_model.trainable = True\n",
        "for layer in base_model.layers[:100]:  # Freeze layers before the fine-tuning cut-off\n",
        "    layer.trainable = False\n",
        "\n",
        "# Re-compile the model for fine-tuning\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(1e-5),  # Lower learning rate for fine-tuning\n",
        "              loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Continue training\n",
        "history_fine = model.fit(train_norm, epochs=20, validation_data=test_norm, callbacks=[lr_scheduler])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kVW_FdmX-Y36"
      },
      "outputs": [],
      "source": [
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(test_norm, steps=len(test_norm))\n",
        "print('Test accuracy:', test_acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x6A9yd31hEpG"
      },
      "source": [
        "## Plot loss curves, visualize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PbR3yHAZotht"
      },
      "outputs": [],
      "source": [
        "# Let's visualize our images\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import random\n",
        "\n",
        "def view_random_image(target_dir, target_class):\n",
        "  # Set up the target directory (we'll view images from here)\n",
        "  target_folder = target_dir + target_class\n",
        "\n",
        "  # Get a random image path\n",
        "  random_image = random.sample(os.listdir(target_folder), 1)\n",
        "\n",
        "  # Read the image and plot it using matplotlib\n",
        "  image = mpimg.imread(target_folder + \"/\" + random_image[0])\n",
        "  plt.imshow(image)\n",
        "  plt.title(f\"Target Class: {target_class}\")\n",
        "  plt.axis(\"off\");\n",
        "\n",
        "  print(f\"Image shape: {image.shape}\") # show the shape of the image\n",
        "\n",
        "  return image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FkweU6f_ouRA"
      },
      "outputs": [],
      "source": [
        "view_random_image(\"/content/Animals/train/\", \"dog\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R3z9NR8Xg7ch"
      },
      "outputs": [],
      "source": [
        "# Let's create a function to plot our loss curves\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_loss_curves(history):\n",
        "  \"\"\"\n",
        "  Returns seperate loss curves for training and validation metrics.\n",
        "  \"\"\"\n",
        "  loss = history.history[\"loss\"]\n",
        "  val_loss = history.history[\"val_loss\"]\n",
        "\n",
        "  accuracy = history.history[\"accuracy\"]\n",
        "  val_accuracy = history.history[\"val_accuracy\"]\n",
        "\n",
        "  epochs = range(len(history.history[\"loss\"])) # how many epochs did we run for\n",
        "\n",
        "  # Plot loss\n",
        "  plt.plot(epochs, loss, label=\"training_loss\")\n",
        "  plt.plot(epochs, val_loss, label=\"validation_loss\")\n",
        "  plt.title(\"Loss\")\n",
        "  plt.xlabel(\"Epochs\")\n",
        "  plt.legend();\n",
        "\n",
        "  # Plot accuracy\n",
        "  plt.figure()\n",
        "  plt.plot(epochs, accuracy, label=\"accuracy\")\n",
        "  plt.plot(epochs, val_accuracy, label=\"val_accuracy\")\n",
        "  plt.title(\"Accuracy\")\n",
        "  plt.xlabel(\"Epochs\")\n",
        "  plt.legend();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F0kAGHoJg-_I"
      },
      "outputs": [],
      "source": [
        "plot_loss_curves(history)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KjVo3sDJh3I0"
      },
      "source": [
        "# Let's make function to predict and plot custom image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nSjeSML9iP5p"
      },
      "outputs": [],
      "source": [
        "# Get image\n",
        "# !wget \"https://raw.githubusercontent.com/traizooo/TensorFlow/main/motyl1.jpg\"\n",
        "image = \"spider.jpeg\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vfslop3v_9Xs"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "import numpy as np\n",
        "\n",
        "img = load_img(image, target_size=(224, 224))\n",
        "\n",
        "img_array = img_to_array(img)\n",
        "img_array = img_array.reshape((1,) + img_array.shape)\n",
        "img_array = img_array / 255.\n",
        "\n",
        "pred = model.predict(img_array)\n",
        "class_idx = np.argmax(pred[0])\n",
        "\n",
        "class_map = train_norm.class_indices\n",
        "label = list(class_map.keys())[list(class_map.values()).index(class_idx)]\n",
        "\n",
        "# Print the predicted class label\n",
        "plt.imshow(img)\n",
        "plt.axis(False)\n",
        "print(\"Predicted class:\", label)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Saving model"
      ],
      "metadata": {
        "id": "7tHh8ZT9wjxm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('animals-recon-model')"
      ],
      "metadata": {
        "id": "0YIbkqzcV_4w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Zip the saved model directory\n",
        "!zip -r animals-recon-model.zip animals-recon-model\n",
        "\n",
        "# Download the zip file\n",
        "from google.colab import files\n",
        "files.download('animals-recon-model.zip')"
      ],
      "metadata": {
        "id": "Sic-w9xppd4n",
        "outputId": "2f625d77-5be7-485d-9e80-747e5b438ea5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: animals-recon-model/ (stored 0%)\n",
            "  adding: animals-recon-model/assets/ (stored 0%)\n",
            "  adding: animals-recon-model/saved_model.pb (deflated 91%)\n",
            "  adding: animals-recon-model/variables/ (stored 0%)\n",
            "  adding: animals-recon-model/variables/variables.index (deflated 78%)\n",
            "  adding: animals-recon-model/variables/variables.data-00000-of-00001 (deflated 8%)\n",
            "  adding: animals-recon-model/keras_metadata.pb (deflated 96%)\n",
            "  adding: animals-recon-model/fingerprint.pb (stored 0%)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_3dfc9893-2b4e-4e8a-82be-408260d4d61f\", \"animals-recon-model.zip\", 812191651)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QJNhuoJQqGUF"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1RB36uO8YD_LJrVwIpM9cTxTrdFUCHa8e",
      "authorship_tag": "ABX9TyMi5Xu74B2N61SCzF2IhtC8",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}